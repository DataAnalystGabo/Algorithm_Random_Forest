{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest**\n",
    "\n",
    "---\n",
    "\n",
    "Random Forest es un **algoritmo de aprendizaje automático** de uso común, registrado por Leo Breiman y Adele Cutler, que combina el resultado de múltiples árboles de decisión para llegar a un resultado único. Su facilidad de uso y flexibilidad han impulsado su adopción, ya que maneja problemas de clasificación y regresión. [1]\n",
    "\\\n",
    "\\\n",
    "Pero, ¿qué son los árboles de decisión? Son estructuras algorítmicas que se inician con una pregunta. A partir de ahí, pueden subdividirse en una secuencia de preguntas para determinar una respuesta de tipo binario.\n",
    "\\\n",
    "\\\n",
    "Estas preguntas constituyen los nodos de decisión en el árbol, que funcionan como un medio para dividir los datos. Cada pregunta ayuda a determinar una decisión final denominada \"nodo hoja\" o \"leaf node\".\n",
    "\\\n",
    "\\\n",
    "Con el objetivo de profundizar en el entendimiento de los conceptos matemáticos, estadísticos, probabilísticos, computacionales y de programación que subyacen al algoritmo de Random Forest, he asumido la enorme empresa de programarlo desde sus cimientos hasta su puesta en funcionamiento, para finalmente comparar su rendimiento con lo ofrecido por una de las librerías más populares de Machine Learning: Scikit-learn.\n",
    "\\\n",
    "\\\n",
    "[1] IBM, _\"¿Qué es el Random Forest?\"_ [Online]. Available: https://www.ibm.com/mx-es/topics/random-forest. [Accessed: 28-Feb-2025].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TreeNode:** el átomo de los Árboles de Decisión.\n",
    "\n",
    "---\n",
    "\n",
    "Los Árboles de Decisión son un tipo de algoritmo de aprendizaje supervisado no paramétrico. Están compuestos por una estructura jerárquica de árbol, que consta de un nodo raíz, ramas, nodos internos y nodos hoja. [2]\n",
    "\n",
    "Los nodos representan el punto de decisión en donde el algoritmo debe optar por un camino. El **nodo raíz** es el subconjunto de datos inicial. Los **nodos internos** de decisión son aquellos estadios intermedios que permiten ramificar aún más la toma de decisiones. Finalmente, cuando el algoritmo obtiene un valor de predicción y detiene la división del subconjunto de datos, se lo considera un **nodo hoja**.\n",
    "\n",
    "**TreeNode** es la clase que abstrae las características de los nodos y nos permite instanciar los distintos tipos. Los parámetros contenidos son:\n",
    "\n",
    "-   **feature_index:** índice de la variable utilizada para dividir el nodo.\n",
    "-   **threshold:** valor umbral para la división.\n",
    "-   **left:** nodo hijo izquierdo.\n",
    "-   **right:** nodo hijo derecho.\n",
    "-   **value:** valor predictorio para los nodos hoja.\n",
    "\n",
    "[2] IBM, \"¿Qué es un árbol de decisión?\" [Online]. Available: https://www.ibm.com/es-es/think/topics/decision-trees. [Accessed: 28-Feb-2025].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TreeNode import TreeNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_node = TreeNode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_node = TreeNode(feature_index=2, threshold=3.5, left=leaf_node, right=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodo hoja:  {'feature_index': None, 'threshold': None, 'left': None, 'right': None, 'value': None}\n",
      "Nodo interno:  {'feature_index': 2, 'threshold': 3.5, 'left': <TreeNode.TreeNode object at 0x000001ADFC8CD310>, 'right': None, 'value': None}\n"
     ]
    }
   ],
   "source": [
    "print(\"Nodo hoja: \", leaf_node.__dict__)\n",
    "print(\"Nodo interno: \", internal_node.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mecanismos de decisión**\n",
    "\n",
    "---\n",
    "\n",
    "La entropía es una métrica que nos permite calcular la impureza de un conjunto de datos es decir, su grado de desorden o incertidumbre. Existe otra métrica muy utilizada en los algoritmos de Random Forest; la medida de Gini. Sin embargo, para este ejercicio práctico usaremos la entropía como mecanismo de decisión.\n",
    "\\\n",
    "\\\n",
    "Basándonos en la naturaleza del problema a resolver de este proyecto, simulemos un ejemplo. Tenemos cuatro escenarios:\n",
    "\\\n",
    "\\\n",
    "Escenario 1: 5 emails son spam y otros 5 emails no lo son.\n",
    "\\\n",
    "Escenario 2: 7 emails son spam y otros 3 emails no lo son.\n",
    "\\\n",
    "Escenario 3: 9 emails son spam y otros 1 emails no lo son.\n",
    "\\\n",
    "Escenario 4: los 10 emails son spam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from entropy import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emails spam -> 1\n",
    "# Emails no spam -> 0\n",
    "scenary_one = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
    "scenary_two = np.array([1, 1, 1, 1, 1, 1, 1, 0, 0, 0])\n",
    "scenary_three = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0])\n",
    "scenary_four = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ecuación de la entropía total de un sistema (o conjunto de datos en nuestro caso) viene dada por:\n",
    "\n",
    "$$\n",
    "H(x) = - \\sum_{x=0}^{n} p(x) \\log_2(p(x))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy scenary one:  1.0\n",
      "Entropy scenary two:  0.8812908992306927\n",
      "Entropy scenary three:  0.4689955935892812\n",
      "Entropy scenary four:  -0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy scenary one: \", entropy(scenary_one))\n",
    "print(\"Entropy scenary two: \", entropy(scenary_two))\n",
    "print(\"Entropy scenary three: \", entropy(scenary_three))\n",
    "print(\"Entropy scenary four: \", entropy(scenary_four))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "random_forest_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
